---
layout: archive
title: ""
permalink: /research/
author_profile: true
---

{% if author.googlescholar %}
  You can also find my articles on <u><a href="{{author.googlescholar}}">my Google Scholar profile</a>.</u>
{% endif %}



Whether it is music, speech, screams, or environmental sounds, **we make sense of sounds**. It seems trivial because it happens so rapidly and efficiently for most of us but its failure has serious consequences. To understand how it works (or does not work), I focus on different levels of analysis (à la Marr). Understanding the neurobiological mechanisms underlying the cognitive processes at play to make sense of sounds requires the definition of both the activities themselves (i.e., what does the system do/use and what is it good for) and the processes involved in performing such actions (i.e., how does it do it).

Concretely, my daily activities turn around the acoustic description of categories (or mental representation of something abstract such as correctness, beauty, communication intention) and how they are processed.

Here are some examples of current research projects:


Does it sound right? Perception of correctness in music
======

Listeners can easily say if a singer sounds in tune or out of tune (Larrouy-Maestri et al., 2013, 2015) and if a band plays on the beat or not. In fact, we are used to “categorize” what we hear and identify performances sounding wrong. However, as is true for several types of judgments (e.g., beauty or obscenity), the definition of ‘correctness’ in music lacks precision, and the foundation of such categorization remains unclear (Larrouy-Maestri, under review). This project examines what ‘correctness’ means in different musical contexts and the cognitive processes behind such categorization. To do so, we investigate auditory processing of manipulated sequences with methods from psychophysics, physiology and electrophysiology. By comparing ‘correctness’ perception across pitch and time dimensions and examining potential listeners’ profiles, this project aims at clarifying the mechanisms underlying music perception.


Sound categorization
======
Forthcoming


Cognitive process behind prosodic perception
======
The tone of the voice carries information about the emotional state or intention of a speaker. Whereas the nature of acoustic features of contrasted prosodic signals has attracted a lot of attention in the last decades (particularly since Banse & Scherer, 1996), the communication of emotions/intentions remains poorly understood. Also, most of listeners seem to share the ‘code’ (or interpret adequately a prosodic signal) to access emotions/intentions of speakers but misunderstandings easily occur.

This project focuses on the cognitive processes involved in prosody comprehension. More specifically, we examine the categorization of utterances based on the integration of dynamic acoustic information with methods from psychophysics and electrophysiology. By clarifying how listeners deal (or fail to deal) with acoustic information carried by the tone of voice, we aim at better understanding a crucial human ability, that is, the communication of emotions/intentions through speech.

Short to long timescales
======
Music, like speech, can be described as a continuous stream of sounds that is parsed in units of different length. While tones are usually defined as the smallest discrete unit in Western music, we recently provided empirical evidence for the specific role of smaller units in music: scoops, which are small dynamic pitch change at the start or end of sung notes within a melody (Larrouy-Maestri & Pfordresher, 2018, Larrouy-Maestri, Poeppel, & Pfordresher, in press). Together with Xiangbin Teng and David Poeppel, we focused on longer sequences and identified a neural signature that reliably tracks musical phrases (>5 seconds) online. Recently joined by Lea Fink and Zofia Hobubowska on this project, we further explore how such signature contributes to music listening behaviour/enjoyment.

By identifying relevant information at different timescales and understanding how humans deals with such information, this line of research aims at enlightening both music cognition and neurophysiological processing of auditory sequences.

Roots of singing evaluation
======
Forthcoming


*Current collaboration with*
======
Melanie Wald-Fuhrmann<br />
David Poeppel<br />
Daniela Sammler<br />
Lauren Fink<br />
Xiangbin Teng<br />
Lea Fink<br />
Marc Pell<br />
Winfried Menninghaus<br />
Simone Dalla Bella<br />
Pol van Rijn<br />
Vanessa Kegel<br />
Natalie Holz<br />
Claire Pelofi<br />

*Current supervision of*
======
Camila Bruder<br />
Madita Hoerster<br />
Zofia Hobubowska<br />
