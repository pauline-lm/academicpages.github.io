---
layout: archive
title: "Research"
permalink: /research/
author_profile: true
---

{% if author.googlescholar %}
  You can also find my articles on <u><a href="{{author.googlescholar}}">my Google Scholar profile</a>.</u>
{% endif %}


About my research [forthcoming!]

Whether it is music, speech, screams, or environmental sounds, **we make sense of sounds**. It seems trivial because it happens so rapidly and efficiently for most of us but its failure has serious consequences. To understand how it works (or does not work), I focus on different levels of analysis (à la Marr). Understanding the neurobiological mechanisms underlying the cognitive processes at play to make sense of sounds requires the definition of both the activities themselves (i.e., what does the system do/use and what is it good for) and the processes involved in performing such actions (i.e., how does it do it).

Concretely, my daily activities turn around the acoustic description of categories (or mental representation of something abstract such as correctness, beauty, communication intention) and how they are processed. Here are some examples of current research projects:


Does it sound right? Perception of correctness in music
======

Listeners can easily say if a singer sounds in tune or out of tune (Larrouy-Maestri et al., 2013, 2015) and if a band plays on the beat or not. In fact, we are used to “categorize” what we hear and identify performances sounding wrong. However, as is true for several types of judgments (e.g., beauty or obscenity), the definition of ‘correctness’ in music lacks precision, and the foundation of such categorization remains unclear (Larrouy-Maestri, under review). This project examines what ‘correctness’ means in different musical contexts and the cognitive processes behind such categorization. To do so, we investigate auditory processing of manipulated sequences with methods from psychophysics, physiology and electrophysiology. By comparing ‘correctness’ perception across pitch and time dimensions and examining potential listeners’ profiles, this project aims at clarifying the mechanisms underlying music perception.


Sound categorization
======
Forthcoming


Cognitive process behind prosodic perception
======
The tone of the voice carries information about the emotional state or intention of a speaker. Whereas the nature of acoustic features of contrasted prosodic signals has attracted a lot of attention in the last decades (particularly since Banse & Scherer, 1996), the communication of emotions/intentions remains poorly understood. Also, most of listeners seem to share the ‘code’ (or interpret adequately a prosodic signal) to access emotions/intentions of speakers but misunderstandings easily occur.

This project focuses on the cognitive processes involved in prosody comprehension. More specifically, we examine the categorization of utterances based on the integration of dynamic acoustic information with methods from psychophysics and electrophysiology. By clarifying how listeners deal (or fail to deal) with acoustic information carried by the tone of voice, we aim at better understanding a crucial human ability, that is, the communication of emotions/intentions through speech.

Short to long timescales
======
Forthcoming


*Current collaboration with*
======
Melanie Wald-Fuhrmann<br />
David Poeppel<br />
Daniela Sammler<br />
Lauren Fink<br />
Xiangbin Teng<br />
Lea Fink<br />
Marc Pell<br />
Winfried Menninghaus<br />
Simone Dalla Bella<br />
Pol van Rijn<br />
Vanessa Kegel<br />
Natalie Holz<br />
Claire Pelofi<br />

*Current supervision of*
======
Camila Bruder<br />
Madita Hoerster<br />
Zofia Hobubowska<br />
